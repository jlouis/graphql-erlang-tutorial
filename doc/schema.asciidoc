[[schema]]

== GraphQL Schema

With a Mnesia database at our disposal, we next create a GraphQL
schema definition. This file describes the contract between the client
system and the server system. It is used by the GraphQL system to know
which queries are valid and which aren't.

In accordance with OTP design principles, we place this schema inside
a projects `priv` directory. Our GraphQL system can then refer to the
private directory of the application in order to load this schema when
the system boots up.

[[identity-encoding]]
=== Identity encoding

In GraphQL, you have a special type, _ID_, which is used to attach an
identity to objects. It is typically used as a globally
unique identifier for each object in the graph. Even across different
object types; no two objects share a ID, even if they are of different
type.

The _ID_ is always generated by the server. Hence, a client must only
treat an _ID_ as an opaque string value and never parse on the string
value. It can only return the _ID_ value back to the server later on.

To make this more obvious, GraphQL implementations usually base64 encode
their ID-values. In Mnesia, our rows IDs will be integers, and they
will overlap between different types/tables in the database. Since IDs
should be globally unique, we use an encoding in GraphQL. The Starship
with id 3 will be encoded as `base64("Starship:3")`. And the planet
Tatooine taken from the <<system-tour>> is encoded as
`base64("Planet:1")`. This definition somewhat hides the
implementation and also allows the server backend to redefine IDs
later for objects. Another use of the encoding is that it can define
what datasource a given came from, so you can figure out where to find
that object. It is highly useful in migration scenarios.

The encoder is simple because we can assume the server provides valid
values:

[source,erlang]
----
include::{sw_core}/src/sw_core_id.erl[tags=idEncode]
----

The decoder is a bit more involved. It requires you to fail on invalid
inputs. We usually don't need to know what was invalid. We can simply
fail aggressively if things turns out bad. A debugging session will
usually uncover the details anyway as we dig into a failure.

[source,erlang]
----
include::{sw_core}/src/sw_core_id.erl[tags=idDecode]
----

=== The Node Interface

The {relay} specification (see <<relay-modern>>) contains a standard
for an _Object Identification_ interface. Our schema implements this
standard in order to make integration simpler for clients supporting
the standard. The interface, also called the *Node* interface because
of its type, allows you to "`start from`" any node in the graph which
has an _id_ field. That is, every node with identity can be a starting
point for a query.

The interface is most often used as a way to refresh objects in a
client cache. If the client has a stale object in the cache, and the
object has identity, then you can refresh a subset of the graph,
setting out from that object.

The interface specification follows the standard closely:

[source,graphql]
----
include::{sw_core}/priv/sw.schema[tags=nodeInterface]
----

.On Documentation

The Erlang version of GraphQL allows a certain extension by the
https://github.com/apollographql[Apollo Community @ *Github*], who are
building tools GraphQL in general. This extension allows you to use
<<annotations>> in GraphQL schemas to attach more information to
particular objects of interest. We use this for documentation. You can
annotate almost anything with `+description(text: "documentation")`
which in turn attaches that documentation to an entity in the Graph.

Multi-line comments are also possible by using a backtick (`) rather
than a quote symbol ("). These allows larger Markdown entries to be
placed in the documentation, which tends to be good for documentation
of APIs.

NOTE: You can't easily use a backtick (`) inside the multiline
quotations. This means you can't easily write pre-formatted code
sections unless you use indentation in the Markdown format. The choice
was somewhat deliberate in that there is a workaround currently, and
it tends to flow really well when you enter documentation by means of
the backtick character. A future version of the parser might redo this
decision.

=== Object types

We follow the specification for describing object types. Thus, if you
describe an object like a starship as `type Starship { ... }` the
system knows how to parse and internalize such a description. In the
following, we don't cover all of the schema, but focus on a single
type in order to describe what is going on.

==== Planets

Since we have planets in the Mnesia database from the previous
section, we can define the GraphQL Schema for them as well. The
definition is quite straightforward given the Star Wars API we are
trying to mimic already contains all the important parts.

For brevity, we omit the documentation of each individual field for
now. Though a more complete implementation would probably include
documentation on each field to a fine detail.

[source,graphql]
----
include::{sw_core}/priv/sw.schema[tags=planetObject]
----

[[queries-and-mutations]]
=== Queries & Mutations

[[query-object]]
==== Query Object

All GraphQL queries are either a _query_ or a _mutation_.footnote:[The
spec has toyed with the idea of adding more classes in addition to
queries and mutations. Most notably the concept of a _subscription_]
Correspondingly, the schema specification contains entries for two
(output) objects, which are commonly called `Query` and `Mutation`
respectively. For example, the query object looks like:

[source,graphql]
----
include::{sw_core}/priv/sw.schema[tags=queryObject]
----

The Query object defines the (public) query/read API of your backend.
All queries will start from here, and the specification defines what
you can do with the given query.

NOTE: The introspection capabilities of GraphQL will have the astute
reader recognize that this predefined rule of what you can do with a
query is very close to automatic discovery of capabilities. In other
words, you get close to the notion of <<HATEOAS>>, while not reaching
it.

The field `node` allows you to request any node in the Graph. Later,
we will see how to implement the backend functionality for this call.
In this example, we will request a *Starship* through the node
interface by first requesting anything implementing the *Node*
interface, and then use an inline-fragment in order to tell the system
which fields we want to grab inside the starship:

[source,graphql]
----
query StarShipQuery($id : ID!) {
    node(id: $id) {
       __typename
       id
       ... on Starship {
          model
          name
       }
    }
}
----

Fields such as `allStarships` are in the schema in order to make it
easier to peruse the API. In a real system, such a query would be
dangerous since it potentially allows you to request very large data
sets. In practice you would use pagination or use a search engine to
return such results. Specifically, you would never return all possible
values, but only a subset thereof.

[[mutation-object]]
==== Mutation Object

The *Query* object concerns itself about reading data. The *Mutation*
object is for altering data. In a <<cqrs>> understanding, the
*Mutation* object is the _command_.

GraphQL treats mutations the same way as queries except for one subtle
detail: queries may be executed in parallel on the server side whereas
a mutation may not. Otherwise, a mutation works exactly like a query.

Because queries and mutations are the same for the GraphQL engine, we
need to build up conventions in the mutation path in order to make
things work out. First, since mutations starts off from the *Mutation*
object, we can add fields to that object which isn't present in the
Graph otherwise. This allows us to execute transactions at the server
side for changes.

Each transaction becomes a field on the *Mutation* object. And the
result type of the given field is the return value of the mutation.
This return type, often called the _payload_ contains other objects in
the graph. It allows a client to run a mutation on the server side and
then query on the data it just changed. This corresponds to the
situtation in RESTful models where a POST provides a `location:`
response header containing the URI of the newly created object. But as
we want to avoid a roundtrip, we "`bake`" the query into the mutation
in GraphQL.

.sw.schema
[source,graphql]
----
include::{sw_core}/priv/sw.schema[tags=mutationObject]
----

Our mutation object grants a client access to a number of commands it
can execute. First, it can create new factions by means of the
`introduceFaction` field on the object. It can also create a new
*Starship* through the `introduceStarship` field.

Both fields take a single parameter, `input` of a given type (which we
will explain later). It provides data relevant to the given mutation. The
return value is a regular output type in the graph, for instance
*IntroduceStarshipPayload*:

[source,graphql]
----
include::{sw_core}/priv/sw.schema[tags=introduceStarshipPayload]
----

It is common that a payload-style object returns every object which
was manipulated as part of the update. In this case, since starship
introduction creates a new starship and refers to a faction, we return
the fields `starship` and `faction`. It allows a client to execute
queries pertaining to the current situation. Suppose for example we
add a new starship to a faction. We'd like the starship count of that
faction. This is easy due to the payload object. Factions have a
*StarshipConnection*, so we can just utilize that to get the count:

[source,graphql]
----
mutation IF($input : IntroduceStarshipInput!) {
  introduceStarship(input: $input) {
    starship {
      id
      name
    }
    faction {
      id
      name
      ships {
        totalCount
      }
    }
  }
}
----

It is typical use to get "`cross-talk`" updates like this in GraphQL
when you refresh objects in the cache, or when you change the data
through a mutation. 

The mutations given here follow the conventions Facebook has defined
for {relay} and a further treatment is given in the section
<<inputs-and-payloads>>.

=== Input objects

The type system of GraphQL is "`moded`" as in Prolog/Twelf/Mercury or
is "`polarized`" in the sense of type systems and semantics. Some data
has "`positive`" mode/polarity and flows from the client to the
server. Some data has "`negative`" mode/polarity and flows from the
server to the client. Finally, some data are unmoded and can flow in
either direction.

GraphQL distinguishes between _input_ and _output_ types. An input is
positive and an output is negative. While at first, this might seem
like a redundant and bad idea, our experience is that it helps a lot
once your system starts to grow.

In GraphQL, the way you should think about Mutations are that they are
"`stored procedures`" in the backend you can execute. You don't in
general get access to a command which says "`PUT this object back`".
Rather, you get access to a mutation which alters the object in some
predetermined way: `favoriteStarship(starshipId: ID!)` for instance.

Because of this, GraphQL is built to discriminate between what types
of data the client can send and what types of data the server can
respond with.

Input and output objects are subject to different rules. In
particular, there is no way to input a `null` value in an input. The
way a client inputs a _no value_ input is by omission of the input
parameter in question. This choice simplifies clients and servers.

There are times where the client wants to input a number of values at
the same time. You could add more parameters to the field:

[source,graphql]
----
type Mutation {
    introduceStarship(name: String,
                      class: String,
                      manufacturers: [String], ....)
       : IntroduceStarshipPayload
}
----

but this often gets unwieldy in the longer run. Rather than this, you
can also solve the problem by creating an _input object_ which only
works in the input direction:

[source,graphql]
----
include::{sw_core}/priv/sw.schema[tags=introduceStarshipInput]
----
<1> Default parameter value, see <<schema-default-values>>.

In turn, the client can now input all these values as one. Grouping of
like parameters are quite common in GraphQL schemas. Note how input
object fields are often vastly different from the output object it
corresponds to. This is the reason why having two worlds--input &
output--is  useful.

NOTE: The input object presented here doesn't contain a full starship
input. In a full solution, you would provide means to add in pilots,
films, hyperdrive ratings and so on.

It is possible to define default parameters in the schema as well, as
seen in the above example. This is highly useful as a way to simplify
the backend of the system. By providing sensible defaults, you can
often avoid a specialized code path which accounts for an unknown
value. It also simplifies the client as it doesn't have to input all
values unless it wants to make changes from the defaults. Finally it
documents, to the client, what the defaults are.

==== clientMutationId

By now, you have seen that an input object has a `clientMutationId`
and the corresponding payload also has a `clientMutationId`. This is
part of {relay} conventions.

Every *...Input* object in a mutation contains a field `clientMutationId`
which is an optional string. The server reflects the contents of
`clientMutationId` back to the client in its *...Payload* response. It
is used by clients to determine what request a given response pertains
to. The client can generate a UUID say, and send it round-trip to the
server. It can then store a reference to the UUID internally. Once the
response arrives, it can use the `clientMutationId` as a correlation
system and link up which request generated said response.

The solution allows out-of-order processing of multiple mutations at
the same time by the client. In an environment where you have no true
parallelism and have to simulate concurrency through a continuation
passing style, it tends to be useful.

We will later on see how to implement a "`middleware`" which handles
the mutation IDs globally in the system once and for all.

[[interfaces-and-unions]]
=== Interfaces & Unions

In GraphQL, an interface is a way to handle the heterogeneous nature of
modern data. Several objects may share the same fields with the same
types. In this case, we can provide an `interface` for those fields
they have in common.

Likewise, if we have two objects which can logically be the output of
a given field, we can use a `union` to signify that a set of disparate
objects can be returned.

In the case of an interface, the client is only allowed to access the
fields in the interface, unless it fragment-expands in order to be
more specific. For unions, the client _must_ fragment expand to get
the data.

The Star Wars Schema has an obvious example of an interface via the
*Node* specification above, but there is another interface possible in
the specification: both *Starship* and *Vehicle* shares a large set of
data in the concept of a *Transport*. We can arrange for this overlap
by declaring an interface for transports:

[source,graphql]
----
include::{sw_core}/priv/sw.schema[tags=transportInterface]
----

And then we include the interface when we declare either a starship or
a vehicle. Here we use the *Starship* as an example:

[source,graphql]
----
include::{sw_core}/priv/sw.schema[tags=starshipObject]
...
----

.Abstract types

Interfaces and Unions are so-called _abstract types_ in the GraphQL
specification. They never occur in concrete data, but is a type-level
relationship only. Thus, when handling an interface or a union, you
just return concrete objects. In the section <<type-resolution>> we
will see how the server will handle abstract types.

TIP: If you have an object which naturally shares fields with other
objects, consider creating an interface--even in the case where you
have no use for the interface. {project} contains a schema
validator which will validate your fields to be in order. It is fairly
easy to mess up schema types in subtle ways, but if you write them
down, the system can figure out when you make this error.

[[schema-default-values]]
=== Schema default values

In the schema, it is possible to enter default values: `field : Type =
Default`. We already saw an example of this in the section on inputs
for introducing starships.

Defaults can be supplied on input types in general. So input objects
and field arguments can take default values. When a client is omitting
a field or a parameter, it is substituted according to GraphQL rules
for its input default.

This is highly useful because you can often avoid code paths which
fork in your code. Omission of an array of strings, say, can be
substituted with the default `[]` which is better than `null` in
Erlang code in many cases. Default counters can be initialized to some
zero-value and so on. Furthermore, in the schema a default will be
documented explicitly. So a client knows what the default value is and
what is expected. We advise programmers to utilize schema defaults
whenever possible to make the system easier to work with on the client
and server side.

Schema defaults must be type-valid for the type they have. You can't
default a string value in for an integer type for instance. Also, the
rule is that _non-null_ yields to default values. If a default value
is given, it is as if that variable is always given (See the GraphQL
specification on coercion of variable values).

== Loading the Schema

In order to work with a schema, it must be loaded. We can load it as
part of booting the `sw_core` application in the system. After having
loaded the supervisor tree of the application, we can call out and
load the star wars schema into the system. The main schema loader is
defined in the following way:

[source,erlang]
----
include::{sw_core}/src/sw_core_app.erl[tags=loadSchema]
----

To load the schema, we figure out where it is in the file system. The
schema to load is in an environment variable inside `sw_core.app`, and
we let OTP figure out where the applications private directory is.
Then the schema is loaded according to the mapping rules of the
schema.

After the schema loads, we set up a _schema root_ which is how to
start out a _query_ or a _mutation_. Finally, we validate the schema.
This runs some correctness checks on the schema and fails if the
sanity checks don't pass. It forces you to define everything you
use, and it also verifies that interfaces are correctly implemented.

NOTE: Currently, the schema root is set up "`manually`" outside the
schema definition. It is likely that a later version of the
implementation will be able to do this without manually injecting the
root, but by having the root being part of the schema definition.

TIP: Always run the schema validator once you've finished assembling
your schema. Many errors are caught automatically by the validator,
and it removes the hassle of debugging later. Also, it runs fairly
quickly, so run it as part of your system's boot phase. This ensures
your system won't boot if there is some kind of problem with your
schema definition. If you have a boot-test as part of your testing
framework or CI system, you should be able to use this as a "`schema
type checker`" and weed out some obvious definitional bugs.

=== Root setup

The root setup defines how a query begins by defining what type in the
schema specification is the root for queries and mutations
respectively. By convention, these types are always called `Query` and
`Mutation` so it is easy to find the Root's entry points in the
Graph.

The query root must be injected into the schema so the GraphQL system
knows where to start. This is done in the file `sw_core_app` in the
function `setup_root`:

[source,erlang]
----
include::{sw_core}/src/sw_core_app.erl[tags=setupRoot]
----

=== Mapping rules

The mapping rules of the GraphQL system defines how the types in the
schema maps onto erlang modules. Since many mapping can be coalesced
into one, there is the possibility of defining a `default` mapping
which just maps every unmapped object to the default.

All of the mappings goes from an atom, which is the _type_ in the
Schema you want to map. To an atom, which is the Erlang _module_
handling that particular schema type.

[source,erlang]
----
include::{sw_core}/src/sw_core_app.erl[tags=schemaMapping]
----

==== Scalars

Every scalar type in the schema is mapped through the `scalar` mapping
part. It is quite common a system only has a single place in which all
scalars are defined. But it is also possible to split up the scalar
mapping over multiple modules. This can be useful if you have a piece
of code where some scalars naturally lives in a sub-application of some
kind.

==== Interfaces & Unions

In GraphQL, two kinds of _abstract_ types are defined: interfaces and
unions. Interfaces abstract over concrete types which have some fields
in common (and thus the fields must also agree on types). Unions
abstract over concrete types that has nothing in common and thus
simply defines a heterogeneous collection of types.

For the GraphQL system to operate correctly, execution must have a way
to take an abstract type and make it concrete. Say, for instance, you
have just loaded an object of type *Node*. We don't yet know that it
is a starship, but if the programmer fragment expands on
the *Starship*

[source,graphql]
----
query Q($nid : ID!) {
  node(id: $nid) {
    ... on Starship {
      model
    }
  }
}
----

we need to know if the concrete node loaded indeed _was_ a starship.
The type resolver is responsible for figuring out what concrete type
we have. Commonly, we map both the interface type and the union type
to the same resolver.

The reason this needs to be handled by the programmer is because the
GraphQL system doesn't know about your representation. In turn, it
will call back into your code in order to learn which type your
representation has.

==== Objects

The mapping of objects is likely to have a special mapping for each
object type you have defined. This is because each kind of (output)
object tends to be different and requires its own handler.

Note that it is possible to define the type of the object as an
`atom()` here. This is common in GraphQL for Erlang. You can write
definitions as either atoms or binaries. They are most often returned
as binaries at the moment, however.

NOTE: The choice of using binaries may turn out to be wrong. We've
toyed with different representations of this, and none of them fell
out like we wanted. However, because the nature of GraphQL makes sure
that an enemy cannot generate arbitrary atoms in the system, we could
use atoms in a later version of GraphQL. For now, however, most parts
of the system accepts atoms or binaries, and converts data to binaries
internally.
