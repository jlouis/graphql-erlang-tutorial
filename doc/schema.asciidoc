[[schema]]

== GraphQL Schema

With a Mnesia database at our disposal, we next create a GraphQL
schema definition. This file describes the contract between the client
system and the server system. It is used by the GraphQL system to know
which queries are valid and which aren't.

In accordance with OTP design principles, we place this schema inside
a projects `priv` directory. Our GraphQL system can then refer to the
private directory of the application in order to load this schema when
the system boots up.

=== Identity generation

In GraphQL, you have a special type, _ID_, which is used to attach an
identity to objects. It is often construed as a "`PRIMARY KEY`" of
sorts on objects, such that you can refer to objects uniquely. The
rule is that a client must only treat an _ID_ as an opaque string
value and never parse on the string value. Thus, an _ID_ is
represented as a _String_, but you are not allowed to parse it as a
client.

To make this more obvious, the GraphQL people usually base64 encode
their ID-values. Furthermore, we have the problem that in Mnesia, our
rows IDs will be integers. This means we may have overlapping integers
between different types. To avoid problem, we use a common definition
in GraphQL. The Starship with id 3 will be encoded as essentially
`base64("starship:3")`, apart from the fact we use a binary encoding
of the number. This definition somewhat hides the implementation and
also allows the server backend to redefine IDs later for objects.
Another use of the encoding is that it can define what datasource a
given came from, so you can figure out where to find that object. It
is highly useful in migration scenarios.

The encoder is simple because we can assume the server provides valid
values:

[source,erlang]
----
include::{sw_core}/src/sw_core_id.erl[tags=idEncode]
----

The decoder is a bit more involved. It requires you to fail on invalid
inputs. We usually don't need to know what was invalid. We can simply
fail aggressively if things turns out bad. A debugging session will
usually uncover the details anyway as we dig into a failure.

[source,erlang]
----
include::{sw_core}/src/sw_core_id.erl[tags=idDecode]
----

=== The Node Interface

The Relay Modern specification contains a number of standards for how
to implement different parts of the GraphQL schema. One such standard
is the *Node* interface. This interface allows you to "`start from`"
any node in the graph which has an _id_ field. That is, every node
with identity can be a starting point for a query.

The interface is most often used as a way to cache-refresh objects you
have loaded a long time ago in order to make sure they have the right
kinds of data. The interface specification follows the standard
closely:

[source,graphql]
----
include::{sw_core}/priv/sw.schema[tags=nodeInterface]
----

.On Documentation

The Erlang version of GraphQL allows a certain extension by the Apollo
people. This extension allows you to _annotate_ GraphQL schema data
with more information. In particular, we use this for documentation.
You can annotate almost anything with `+description(text:
"documentation")` which in turn attaches that documentation to an
entity in the Graph.

Multi-line comments are also possible by using a backtick (`) rather
than a quote symbol ("). These allows larger Markdown entries to be
placed in the documentation, which tends to be good for documentation
of APIs.

NOTE: You can't easily use a ` inside the multiline quotations. This
means you can't easily write pre-formatted code sections unless you
use indentation in the Markdown format. The choice was somewhat
deliberate in that there is a workaround currently, and it tends to
flow really well when you enter documentation by means of the backtick
character. A future version of the parser might redo this decision.

=== Starships

Since we have Starships in the mnesia database from the previous
section, we can define the GraphQL Schema for them as well. The
definition is quite straightforward given the Star Wars API we are
trying to mimic already contains all the important parts.

For brevity, we omit the documentation of each individual field for
now. Though a more complete implementation would probably include
documentation on each field to a fine detail. Also note we are cutting
the full implementation short since the full Starship contains
pagination, which we handle in a later section in the documentation.

[source,graphql]
----
include::{sw_core}/priv/sw.schema[tags=starshipObject]
...
----

=== Queries & Mutations

All GraphQL queries are either a _query_ or a _mutation_.footnote:[The
spec has toyed with the idea of adding more classes in additon to
queries and mutations. Most notably the concept of a _subscription_]
Correspondingly, the schema specification contains entries for two
(output) objects, which are commonly called `Query` and `Mutation`
respectively. For example, the query object looks like:

[source,graphql]
----
include::{sw_core}/priv/sw.schema[tags=queryObject]
----

The Query object defines the (public) API of your backend. All queries
will start from here, and the specification defines what you can do
with the given query.

NOTE: The introspection capabilities of GraphQL will have the astute
reader recognize that this predefined rule of what you can do with a
query is very close to automatic discovery of capabilities. In other
words, you get close to the notion of <<HATEOAS>>, while not reaching
it.

The field `node` allows you to request any node in the Graph. Later,
we will see how to implement the backend functionality for this call.
The field `starship` allows you to request a particular starship. In a
way, this is a redundant endpoint, since every starship can also be
requested through the node interface, and then fragment expanded on
starships only:

[source,graphql]
----
query StarShipQuery($id : ID!) {
    node(id: $id) {
       __typename
       id
       ... on Starship {
          model
          name
          <1>
       }
    }
}
----
<1> You would put additional fields here.

== Loading the Schema

In order to work with a schema, it must be loaded. We can load it as
part of booting the `sw_core` application in the system. After having
loaded the supervisor tree of the application, we can call out and
load the star wars schema into the system. The main schema loader is
defined in the following way:

[source,erlang]
----
include::{sw_core}/src/sw_core_app.erl[tags=loadSchema]
----

To load the schema, we figure out where it is in the file system. The
schema to load is in an environment variable inside `sw_core.app`, and
we let OTP figure out where the applications private directory is.
Then the schema is loaded according to the mapping rules of the
schema.

After the schema loads, we set up a _schema root_ which is how to
start out a _query_ or a _mutation_. Finally, we validate the schema.
This runs some correctness checks on the schema and fails of the
sanity checks doesn't pass. It forces you to define everything you
use, and it also verifies that interfaces are correctly implemented.

NOTE: Currently, the schema root is set up "`manually`" outside the
schema definition. It is likely that a later version of the
implementation will be able to do this without manually injecting the
root, but by having the root being part of the schema definition.

TIP: Always run the schema validator once you've finished assembling
your schema. Many errors are caught automatically by the validator,
and it removes the hassle of debugging later. Also, it runs fairly
quickly, so run it as part of your systems boot phase. This ensures
your system won't boot if there is some kind of problem with your
schema definition. If you have a boot-test as part of your testing
framework or CI system, you should be able to use this as a "`schema
type checker`" and weed out some obvious definitional bugs.

=== Root setup

The root setup defines how a query begins by defining what type in the
schema specification is the root for queries and mutations
respectively. By convention, these types are always called `Query` and
`Mutation` so it is easy to find find the Root's entry points in the
Graph.

The query root must be injected into the schema so the GraphQL systems
knows where to start. This is done in the file `sw_core_app` in the
function `setup_root`:

[source,erlang]
----
include::{sw_core}/src/sw_core_app.erl[tags=setupRoot]
----

=== Mapping rules

The mapping rules of the GraphQL system defines how the types in the
schema maps onto erlang modules. Since many mapping can be coalesced
into one, there is the possibility of defining a `default` mapping
which just maps every unmapped object to the default.

All of the mappings goes from an atom, which is the _type_ in the
Schema you want to map. To an atom, which is the Erlang _module_
handling that particular schema type.

[source,erlang]
----
include::{sw_core}/src/sw_core_app.erl[tags=schemaMapping]
----

.Scalars

Every scalar type in the schema is mapped through the `scalar` mapping
part. It is quite common a system only has a single place in which all
scalars are defined. But it is also possible to split up the scalar
mapping over multiple modules. This can be useful if you have a piece
f code where some scalars naturally lives in a sub-application of some
kind.

.Interfaces & Unions

In GraphQL, two kinds of _abstract_ types are defined: interfaces and
unions. Interfaces abstract over concrete types which have some fields
in common (and thus the fields must also agree on types). Unions
abstract over concrete types that has nothing in common and thus
simply defines a heterogenous collection of types.

For the GraphQL system to operate correctly, execution must have a way
to take an abstract type and make it concrete. Say, for instance, you
have just loaded an object of type *Node*. We don't yet know that it
is a starship, but if the programmer fragment expands inside the on
the *Starship*

[source,graphql]
----
query Q($nid : ID!) {
  node(id: $nid) {
    ... on Starship {
      model
    }
  }
}
----

we need to know if the concrete node loaded indeed _was_ a starship.
The type resolver is responsible for figuring out what concrete type
we have. Commonly, we map both the interface and union type resolver
to the same resolver.

The reason this needs to be handled by the programmer is because the
GraphQL system doesn't know about your representation. In turn, it
call back into your code in order to learn which type your
representation has.

.Objects

The mapping of objects is likely to have a special mapping for each
object type you have defined. This is because each kind of (output)
object tend to be different and require its own handler.

Note that it is possible to define the type of the object as an
`atom()` here. This is common in GraphQL for Erlang. You can write
definitions as either atoms or binaries. They are most often returned
as binaries at the moment, however.

NOTE: The choice of using binaries may turn out to be wrong. We've
toyed with different representations of this, and none of them falls
out like you want. However, because the nature of GraphQL makes sure
that an enemy cannot generate arbitrary atoms in the system, we could
use atoms in a later version of GraphQL. For now, however, most parts
of the system accepts atoms or binaries, and converts data to binaries
internally.


